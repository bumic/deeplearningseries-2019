{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "word2vec.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "4BOSaPj1UVxH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Exploring word2vec\n",
        "\n",
        "We will be using a Python package called `gensim` to play around with word2vec.\n",
        "\n",
        "We use word2vec to produce word embedding. This is the way we convert normal text into vectors that can be use to feed into neural networks. These vector has interesting properties that make them superior than using bag-of-word or one-hot vector for vectorizing text."
      ]
    },
    {
      "metadata": {
        "id": "EHOK2aCOMidi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "import gensim.downloader as api"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pGZ-T4RrVTDO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The following command load the word2vec model trained on part of the [Google News dataset](https://code.google.com/archive/p/word2vec/). The dataset has about 100 billion words. This model contained a 300-dimention vector for each of about 3 million words and phrases. \n",
        "\n",
        "Loading the model take a very long time, therefore feels free to try this out on your own time."
      ]
    },
    {
      "metadata": {
        "id": "5yuN4wFCMmmU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = api.load(\"word2vec-google-news-300\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pTDTmXtUJGf3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Most similar vectors\n",
        "\n",
        "`gensim` allows us to quickly find the most similar word vector to a word vector of our chosing through [`model.most_similar()`](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.most_similar). \n",
        "\n",
        "For example, we can see the most similar vector to the word-vector \"king\" has meaning that in the same general area of said word. The most similar vector for the word \"king\" in this example, is the plural form of the word (\"kings\"). This makes sense since the word's plural form shared basically the same \"context\" in sentences with the singular form. It would make sense that the word's plural form being the most similar. \n",
        "\n",
        "We can further look at other similar vector and see that the theme of royalty is well-represented. \n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "EERnK7cnMvwe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.most_similar(\"king\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sz5M8L3JKP0Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "On another example, we trying to look for the similar word-vectors to the word \"Obama\". Here we see that the most similars word-vector are themed around the person or other person who are connected to Obama himself. "
      ]
    },
    {
      "metadata": {
        "id": "TKJTK3biOfGi",
        "colab_type": "code",
        "outputId": "0baad296-d30e-4dcc-8880-d9e10ffd25bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "cell_type": "code",
      "source": [
        "model.most_similar(\"Obama\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Barack_Obama', 0.8036513328552246),\n",
              " ('President_Barack_Obama', 0.7878767848014832),\n",
              " ('McCain', 0.7555227875709534),\n",
              " ('Clinton', 0.7526832222938538),\n",
              " ('Illinois_senator', 0.74974524974823),\n",
              " ('Biden', 0.7485178709030151),\n",
              " ('Bush', 0.7348896861076355),\n",
              " ('Barack', 0.7290467023849487),\n",
              " ('White_House', 0.7151209115982056),\n",
              " ('elect_Barack_Obama', 0.6941337585449219)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "-nsMpeKGO8y9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Try your own word of your choosing. What kind of similarities between the word-vector that are similar to the word that you have chosen?\n",
        "# model.most_similar()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xLfHx7UXKztk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Word-vector \"algebra\"\n",
        "\n",
        "Another interesting property of word-vectors is the ability to do \"algebra\" on it and derives a semantic meaning. \n",
        "\n",
        "For example:\n",
        "$king + woman = queen$\n",
        "\n",
        "Using `gensim`, we can represent this operation through positive word-vectors and negative word-vectors.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "nwX9VKEyKyS1",
        "colab_type": "code",
        "outputId": "0a398bad-7567-434b-fee4-ceaf4b431979",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "cell_type": "code",
      "source": [
        "model.most_similar(positive=[\"king\", \"woman\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('man', 0.6628609895706177),\n",
              " ('queen', 0.6438563466072083),\n",
              " ('girl', 0.6136074662208557),\n",
              " ('princess', 0.6087510585784912),\n",
              " ('monarch', 0.5900576114654541),\n",
              " ('prince', 0.5896844863891602),\n",
              " ('teenage_girl', 0.571865975856781),\n",
              " ('boy', 0.5665285587310791),\n",
              " ('crown_prince', 0.5520807504653931),\n",
              " ('lady', 0.5445604920387268)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "bryC0K9tNKRR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Another example,\n",
        "\n",
        "$China + capital = Beijing$\n",
        "\n",
        "We can see that we are able to derives the country's capital through just word-vector \"algebra\". "
      ]
    },
    {
      "metadata": {
        "id": "Oix5hvs0MmJu",
        "colab_type": "code",
        "outputId": "77088c27-ae54-4916-8df3-dc235c56804b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "cell_type": "code",
      "source": [
        "model.most_similar(positive=[\"China\", \"capital\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Beijing', 0.6323763132095337),\n",
              " ('Chinese', 0.6081547737121582),\n",
              " ('Foods_Limited_HKSE', 0.579767107963562),\n",
              " ('Daniel_Schearf_reports', 0.5684748291969299),\n",
              " ('Shanghai', 0.5660480260848999),\n",
              " ('Guandong_Province', 0.5635813474655151),\n",
              " ('Changsha_Hunan', 0.5617741346359253),\n",
              " ('Communications_BoCom', 0.5575785040855408),\n",
              " ('Guangzhou', 0.5527973175048828),\n",
              " ('Chengdu', 0.5491997003555298)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "xkQCYCIYNo75",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "How about $king - man$ ?"
      ]
    },
    {
      "metadata": {
        "id": "yQ26IGawNIN5",
        "colab_type": "code",
        "outputId": "d5f96a9e-c925-4e84-9eeb-f3e60e8cbb01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "cell_type": "code",
      "source": [
        "model.most_similar(positive=[\"king\"], negative=[\"man\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('kings', 0.4295138418674469),\n",
              " ('queen', 0.39028695225715637),\n",
              " ('Pansy_Ho_Chiu', 0.3827225863933563),\n",
              " ('monarch', 0.3633837103843689),\n",
              " ('kingdom', 0.36145076155662537),\n",
              " ('royal_palace', 0.3535977602005005),\n",
              " ('Savory_aromas_wafted', 0.35272473096847534),\n",
              " ('princes', 0.3526379466056824),\n",
              " ('monarchy', 0.3432357907295227),\n",
              " ('Rama_VII', 0.3380342423915863)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "Gsp3wEA_NwyK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Try playing around with some word-vector \"algebra\" of your own. What more interesting thing could you found about word-vectors?\n",
        "# model.most_similar(positive=[], negative=[])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}